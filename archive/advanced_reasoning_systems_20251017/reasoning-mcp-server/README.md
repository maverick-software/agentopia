# Reasoning MCP Server\n\nThis server provides advanced reasoning capabilities (inductive, deductive, abductive, plan-and-execute) to Agentopia agents via the Model Context Protocol (MCP).\n\n## Prerequisites\n\n- Node.js (version recommended by Agentopia project, e.g., v18+)\n- npm (usually comes with Node.js)\n\n## Setup\n\n1.  Navigate to this directory:\n    ```bash\n    cd services/reasoning-mcp-server\n    ```\n2.  Install dependencies:\n    ```bash\n    npm install\n    ```\n\n## Running the Server\n\n### Development Mode\n\nFor development with live reloading (using `ts-node-dev`):\n\n```bash\nnpm run dev\n```\n\nThe server will typically start on `http://localhost:3001` (MCP endpoint: `http://localhost:3001/mcp`). The port can be configured via the `REASONING_MCP_PORT` environment variable.\n\n### Production Mode\n\n1.  Build the TypeScript source:\n    ```bash\n    npm run build\n    ```\n2.  Start the server:\n    ```bash\n    npm start\n    ```\n    This will run the compiled JavaScript from the `dist` directory.\n\n## Configuration\n\n-   **Port:** The server listens on port 3001 by default. This can be changed by setting the `REASONING_MCP_PORT` environment variable.\n-   **OpenAI API Key:** To enable actual LLM calls (for reasoning types that use them), you must set the `OPENAI_API_KEY` environment variable to your OpenAI API key. If not set, functions attempting to call the LLM will throw an error. 